{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn import over_sampling\n",
    "from sklearn.metrics import roc_curve,auc, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from prettytable import PrettyTable\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1 = pd.read_csv('df_final_1_v1.1.csv.gz')\n",
    "df_final_2 = pd.read_csv('df_final_2_v1.1.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1\n",
    "\n",
    "In this dataset, all missing values (after merging) are removed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final_1.drop(columns=['TARGET'])\n",
    "y = df_final_1['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0.0    92.353584\n",
       "1.0     7.646416\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() / len(y)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label TARGET exhibits extreme class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X_train :  (100972, 178)\n",
      "Dimensi of X_test    :  (25244, 178)\n",
      "Dimensi of y_train   :  (100972,)\n",
      "Dimensi of y_test    :  (25244,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Dimension of X_train : ', X_train.shape)\n",
    "print(f'Dimensi of X_test    : ', X_test.shape)\n",
    "print(f'Dimensi of y_train   : ', y_train.shape)\n",
    "print(f'Dimensi of y_test    : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class imbalance needs to be addressed; otherwise, the model will be biased toward the majority class if left unhandled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Minority Oversampling Technique (SMOTE)\n",
    "X_train_over, y_train_over = over_sampling.SMOTE(sampling_strategy=1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Minority Oversampling Technique (SMOTE) is an effective technique for mitigating the effects of extreme class imbalance, leading to more robust and accurate predictive models. SMOTE generates synthetic samples for the minority class, helping to balance the class distribution. This can improve the model's ability to learn from the underrepresented class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain algorithms are sensitive to outliers and varying data scales, which can lead to misinterpretations of the data. Algorithms that depend on distance calculations, such as k-nearest neighbors (KNN), support vector machines (SVM), and logistic regression, should operate on a common scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_over)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have **X_train_over**, **X_train_scaled**, **X_test**, **X_test_scaled**, **y_train_over**, and **y_test** that will be used in the tested algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def function for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk evaluasi model \n",
    "\n",
    "def model_evaluation(y_true, y_pred, y_pred_proba, model_name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    f2 = fbeta_score(y_true, y_pred, beta=2.0)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "    \n",
    "    results = pd.DataFrame([[model_name, acc, prec, rec, f1, f2, auc]],\n",
    "                       columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\",\n",
    "                                \"F1 Score\", \"F2 Score\", \"roc_auc_score\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk cek overfitting vs underfitting atau best fit\n",
    "def check_model_fit(classifier, X_train, X_val, y_train, y_val, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Membandingkan performa model pada data training dan validation\n",
    "    untuk mendeteksi overfitting/underfitting\n",
    "    \"\"\"\n",
    "    # Prediksi pada data training\n",
    "    y_train_pred = classifier.predict(X_train)\n",
    "    y_train_pred_proba = classifier.predict_proba(X_train)\n",
    "    \n",
    "    # Prediksi pada data validation\n",
    "    y_val_pred = classifier.predict(X_val)\n",
    "    y_val_pred_proba = classifier.predict_proba(X_val)\n",
    "    \n",
    "    # Metrics untuk training\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f2 = fbeta_score(y_train, y_train_pred, beta=2.0)\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_pred_proba[:, 1])\n",
    "\n",
    "    # Metrics untuk validation\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f2 = fbeta_score(y_val, y_val_pred, beta=2.0)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_pred_proba[:, 1])\n",
    "    \n",
    "\n",
    "    # Membuat DataFrame perbandingan\n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'ROC AUC'],\n",
    "        'Training': [train_accuracy, train_precision, train_recall, train_f1, train_f2, train_roc_auc],\n",
    "        'Validation': [val_accuracy, val_precision, val_recall, val_f1, val_f2, val_roc_auc],\n",
    "        'Difference': [train_accuracy - val_accuracy, \n",
    "                      train_precision - val_precision,\n",
    "                      train_recall - val_recall,\n",
    "                      train_f1 - val_f1,\n",
    "                      train_f2 - val_f2,\n",
    "                      train_roc_auc - val_roc_auc]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nModel Fit Analysis for {model_name}:\")\n",
    "    print(comparison.round(4))\n",
    "    \n",
    "    # Analisis overfitting/underfitting\n",
    "    avg_diff = comparison['Difference'].mean()\n",
    "    \n",
    "    print(\"\\nAnalisis:\")\n",
    "    if (train_roc_auc - val_roc_auc) > 0.01:  # Threshold bisa disesuaikan\n",
    "        print(\"⚠️ Model menunjukkan tanda OVERFITTING\")\n",
    "        print(f\"    selisih metrics training-validation: {(train_roc_auc - val_roc_auc):.4f}\")\n",
    "        print(\"   - Model terlalu 'menghapal' data training\")\n",
    "        print(\"   - Performa di validation jauh lebih rendah\")\n",
    "    elif (train_roc_auc - val_roc_auc) < 0.01:  # Threshold bisa disesuaikan\n",
    "        print(\"⚠️ Model menunjukkan tanda UNDERFITTING\")\n",
    "        print(f\"   ROC-AUC training: {train_roc_auc:.4f}\")\n",
    "        print(\"   - Model terlalu simpel\")\n",
    "        print(\"   - Performa rendah bahkan di data training\")\n",
    "    else:\n",
    "        print(\"✅ Model memiliki fit yang baik\")\n",
    "        print(f\"   Rata-rata selisih metrics: {(train_roc_auc - val_roc_auc):.4f}\")\n",
    "        print(\"   - Performa seimbang antara training dan validation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.697354</td>\n",
       "      <td>0.155711</td>\n",
       "      <td>0.668566</td>\n",
       "      <td>0.252592</td>\n",
       "      <td>0.40306</td>\n",
       "      <td>0.751725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0  Logistic Regression  0.697354   0.155711  0.668566  0.252592   0.40306   \n",
       "\n",
       "   roc_auc_score  \n",
       "0       0.751725  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_logreg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "classifier_logreg.fit(X_train_scaled, y_train_over)\n",
    "y_pred = classifier_logreg.predict(X_test_scaled)\n",
    "y_pred_proba = classifier_logreg.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluasi\n",
    "results_logreg = model_evaluation(y_test, y_pred, y_pred_proba, \"Logistic Regression\")\n",
    "results_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Logistic Regression:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.7085      0.6974      0.0112\n",
      "1  Precision    0.7069      0.1557      0.5512\n",
      "2     Recall    0.7124      0.6686      0.0439\n",
      "3         F1    0.7097      0.2526      0.4571\n",
      "4         F2    0.7113      0.4031      0.3083\n",
      "5    ROC AUC    0.7764      0.7517      0.0247\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.0247\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "check_model_fit(\n",
    "    classifier_logreg,\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.849271</td>\n",
       "      <td>0.135409</td>\n",
       "      <td>0.180218</td>\n",
       "      <td>0.154632</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.542453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0  Decision Tree  0.849271   0.135409  0.180218  0.154632  0.169031   \n",
       "\n",
       "   roc_auc_score  \n",
       "0       0.542453  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_dt.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_dt.predict(X_test)\n",
    "y_pred_proba = classifier_dt.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_dt = model_evaluation(y_test, y_pred, y_pred_proba, \"Decision Tree\")\n",
    "classifier_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Decision Tree:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy       1.0      0.8477      0.1523\n",
      "1  Precision       1.0      0.1328      0.8672\n",
      "2     Recall       1.0      0.1792      0.8208\n",
      "3         F1       1.0      0.1526      0.8474\n",
      "4         F2       1.0      0.1675      0.8325\n",
      "5    ROC AUC       1.0      0.5411      0.4589\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.4589\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_dt.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_dt.predict(X_test)\n",
    "y_pred_proba = classifier_dt.predict_proba(X_test)\n",
    "check_model_fit(\n",
    "    classifier_dt,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Decision Tree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.923625</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.00823</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.712299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0  Random Forest  0.923625   0.615385  0.004143   0.00823   0.00517   \n",
       "\n",
       "   roc_auc_score  \n",
       "0       0.712299  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_rf.predict(X_test)\n",
    "y_pred_proba = classifier_rf.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_rf = model_evaluation(y_test, y_pred, y_pred_proba, \"Random Forest\")\n",
    "classifier_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Random Forest:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy       1.0      0.9234      0.0766\n",
      "1  Precision       1.0      0.4000      0.6000\n",
      "2     Recall       1.0      0.0021      0.9979\n",
      "3         F1       1.0      0.0041      0.9959\n",
      "4         F2       1.0      0.0026      0.9974\n",
      "5    ROC AUC       1.0      0.7127      0.2873\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2873\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_rf.predict(X_test)\n",
    "y_pred_proba = classifier_rf.predict_proba(X_test)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_rf,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM (Gradient Boosting Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 93252, number of negative: 93252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 43928\n",
      "[LightGBM] [Info] Number of data points in the train set: 186504, number of used features: 175\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Light GBM</td>\n",
       "      <td>0.92311</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>0.035768</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>0.75513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Precision    Recall  F1 Score  F2 Score  roc_auc_score\n",
       "0  Light GBM   0.92311   0.439024  0.018643  0.035768  0.023059        0.75513"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lgbm = X_train_over.copy()\n",
    "X_test_lgbm = X_test.copy()\n",
    "\n",
    "X_train_lgbm.columns = X_train_lgbm.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '', regex=True)\n",
    "X_test_lgbm.columns = X_test_lgbm.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '', regex=True)\n",
    "\n",
    "classifier_lgbm = LGBMClassifier()\n",
    "classifier_lgbm.fit(X_train_lgbm, y_train_over)\n",
    "y_pred = classifier_lgbm.predict(X_test_lgbm)\n",
    "y_pred_proba = classifier_lgbm.predict_proba(X_test_lgbm)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_lgbm = model_evaluation(y_test, y_pred, y_pred_proba, \"Light GBM\")\n",
    "classifier_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 93252, number of negative: 93252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43928\n",
      "[LightGBM] [Info] Number of data points in the train set: 186504, number of used features: 175\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model Fit Analysis for Light GBM:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9592      0.9231      0.0361\n",
      "1  Precision    0.9990      0.4390      0.5600\n",
      "2     Recall    0.9194      0.0186      0.9007\n",
      "3         F1    0.9575      0.0358      0.9218\n",
      "4         F2    0.9343      0.0231      0.9112\n",
      "5    ROC AUC    0.9848      0.7551      0.2297\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2297\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_lgbm = LGBMClassifier()\n",
    "classifier_lgbm.fit(X_train_lgbm, y_train_over)\n",
    "y_pred = classifier_lgbm.predict(X_test_lgbm)\n",
    "y_pred_proba = classifier_lgbm.predict_proba(X_test_lgbm)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_lgbm,\n",
    "    X_train_lgbm,\n",
    "    X_test_lgbm,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Light GBM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>0.908453</td>\n",
       "      <td>0.266585</td>\n",
       "      <td>0.112377</td>\n",
       "      <td>0.158106</td>\n",
       "      <td>0.127079</td>\n",
       "      <td>0.68279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Precision    Recall  F1 Score  F2 Score  roc_auc_score\n",
       "0  Ada Boost  0.908453   0.266585  0.112377  0.158106  0.127079        0.68279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ab = AdaBoostClassifier()\n",
    "classifier_ab.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_ab.predict(X_test)\n",
    "y_pred_proba = classifier_ab.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_ab = model_evaluation(y_test, y_pred, y_pred_proba, \"Ada Boost\")\n",
    "classifier_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Ada Boost:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9354      0.9085      0.0270\n",
      "1  Precision    0.9697      0.2666      0.7031\n",
      "2     Recall    0.8990      0.1124      0.7866\n",
      "3         F1    0.9330      0.1581      0.7749\n",
      "4         F2    0.9123      0.1271      0.7852\n",
      "5    ROC AUC    0.9701      0.6828      0.2873\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2873\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_ab = AdaBoostClassifier()\n",
    "classifier_ab.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_ab.predict(X_test)\n",
    "y_pred_proba = classifier_ab.predict_proba(X_test)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_ab,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Ada Boost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Boost</td>\n",
       "      <td>0.921922</td>\n",
       "      <td>0.402913</td>\n",
       "      <td>0.042983</td>\n",
       "      <td>0.077679</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>0.736213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Precision    Recall  F1 Score  F2 Score  roc_auc_score\n",
       "0  XGB Boost  0.921922   0.402913  0.042983  0.077679  0.052333       0.736213"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_xgb.predict(X_test)\n",
    "y_pred_proba = classifier_xgb.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_xgb = model_evaluation(y_test, y_pred, y_pred_proba, \"XGB Boost\")\n",
    "classifier_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for XGB Boost:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9648      0.9219      0.0429\n",
      "1  Precision    0.9990      0.4029      0.5961\n",
      "2     Recall    0.9306      0.0430      0.8877\n",
      "3         F1    0.9636      0.0777      0.8859\n",
      "4         F2    0.9435      0.0523      0.8912\n",
      "5    ROC AUC    0.9924      0.7362      0.2562\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2562\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_xgb.predict(X_test)\n",
    "y_pred_proba = classifier_xgb.predict_proba(X_test)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_xgb,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"XGB Boost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 93252, number of negative: 93252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43917\n",
      "[LightGBM] [Info] Number of data points in the train set: 186504, number of used features: 174\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'class_weight': 'balanced', 'colsample_bytree': np.float64(0.6557975442608167), 'learning_rate': np.float64(0.09764339456056544), 'max_depth': 9, 'min_child_samples': 47, 'n_estimators': 150, 'num_leaves': 74, 'subsample': np.float64(0.9932923543227152)}\n",
      "Best CV ROC AUC score: 0.9732743473208721\n",
      "\n",
      "Metrics Comparison:\n",
      "Metric               Train       Test Difference\n",
      "---------------------------------------------\n",
      "accuracy             0.964      0.923      0.041\n",
      "precision            1.000      0.484      0.516\n",
      "recall               0.928      0.031      0.898\n",
      "roc_auc              0.994      0.752      0.242\n",
      "\n",
      "Detailed Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96     23313\n",
      "         1.0       0.48      0.03      0.06      1931\n",
      "\n",
      "    accuracy                           0.92     25244\n",
      "   macro avg       0.70      0.51      0.51     25244\n",
      "weighted avg       0.89      0.92      0.89     25244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Define the parameter space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'num_leaves': randint(20, 100),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_samples': randint(1, 50),\n",
    "    'class_weight': ['balanced', {0: 1, 1: 11.3}]\n",
    "}\n",
    "\n",
    "# Create base model\n",
    "model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Setup RandomizedSearchCV with ROC AUC scoring\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',  # Use ROC AUC for optimization\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best CV ROC AUC score:\", random_search.best_score_)\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Calculate metrics for both train and test sets\n",
    "def get_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y, y_pred),\n",
    "        'precision': precision_score(y, y_pred),\n",
    "        'recall': recall_score(y, y_pred),\n",
    "        'roc_auc': roc_auc_score(y, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Get metrics for both sets\n",
    "train_metrics = get_metrics(best_model, X_train_over, y_train_over)\n",
    "test_metrics = get_metrics(best_model, X_test, y_test)\n",
    "\n",
    "# Print metrics comparison\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "print(f\"{'Metric':<15} {'Train':>10} {'Test':>10} {'Difference':>10}\")\n",
    "print(\"-\" * 45)\n",
    "for metric in train_metrics.keys():\n",
    "    diff = train_metrics[metric] - test_metrics[metric]\n",
    "    print(f\"{metric:<15} {train_metrics[metric]:>10.3f} {test_metrics[metric]:>10.3f} {diff:>10.3f}\")\n",
    "\n",
    "# Print detailed classification report for test set\n",
    "print(\"\\nDetailed Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 93252, number of negative: 93252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43928\n",
      "[LightGBM] [Info] Number of data points in the train set: 186504, number of used features: 175\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model Fit Analysis for Light GBM:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9592      0.9231      0.0361\n",
      "1  Precision    0.9990      0.4390      0.5600\n",
      "2     Recall    0.9194      0.0186      0.9007\n",
      "3         F1    0.9575      0.0358      0.9218\n",
      "4         F2    0.9343      0.0231      0.9112\n",
      "5    ROC AUC    0.9848      0.7551      0.2297\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2297\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_lgbm = LGBMClassifier()\n",
    "classifier_lgbm.fit(X_train_lgbm, y_train_over)\n",
    "y_pred = classifier_lgbm.predict(X_test_lgbm)\n",
    "y_pred_proba = classifier_lgbm.predict_proba(X_test_lgbm)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_lgbm,\n",
    "    X_train_lgbm,\n",
    "    X_test_lgbm,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Light GBM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 2\n",
    "\n",
    "In this dataset, all missing values (after merging) are filled with median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final_2.drop(columns=['TARGET'])\n",
    "y = df_final_2['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0.0    91.908901\n",
       "1.0     8.091099\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() / len(y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X_train :  (243180, 178)\n",
      "Dimensi of X_test    :  (60796, 178)\n",
      "Dimensi of y_train   :  (243180,)\n",
      "Dimensi of y_test    :  (60796,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Dimension of X_train : ', X_train.shape)\n",
    "print(f'Dimensi of X_test    : ', X_test.shape)\n",
    "print(f'Dimensi of y_train   : ', y_train.shape)\n",
    "print(f'Dimensi of y_test    : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Minority Oversampling Technique (SMOTE)\n",
    "X_train_over, y_train_over = over_sampling.SMOTE(sampling_strategy=1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_over)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have **X_train_over**, **X_train_scaled**, **X_test**, **X_test_scaled**, **y_train_over**, and **y_test** that will be used in the tested algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.698566</td>\n",
       "      <td>0.165778</td>\n",
       "      <td>0.676704</td>\n",
       "      <td>0.266314</td>\n",
       "      <td>0.418649</td>\n",
       "      <td>0.752318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0  Logistic Regression  0.698566   0.165778  0.676704  0.266314  0.418649   \n",
       "\n",
       "   roc_auc_score  \n",
       "0       0.752318  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_logreg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "classifier_logreg.fit(X_train_scaled, y_train_over)\n",
    "y_pred = classifier_logreg.predict(X_test_scaled)\n",
    "y_pred_proba = classifier_logreg.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluasi\n",
    "results_logreg = model_evaluation(y_test, y_pred, y_pred_proba, \"Logistic Regression\")\n",
    "results_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Logistic Regression:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.7072      0.6986      0.0086\n",
      "1  Precision    0.7041      0.1658      0.5384\n",
      "2     Recall    0.7147      0.6767      0.0380\n",
      "3         F1    0.7094      0.2663      0.4431\n",
      "4         F2    0.7126      0.4186      0.2939\n",
      "5    ROC AUC    0.7739      0.7523      0.0216\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.0216\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "check_model_fit(\n",
    "    classifier_logreg,\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.842901</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>0.175788</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>0.166001</td>\n",
       "      <td>0.538682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0  Decision Tree  0.842901   0.135764  0.175788  0.153205  0.166001   \n",
       "\n",
       "   roc_auc_score  \n",
       "0       0.538682  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_dt.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_dt.predict(X_test)\n",
    "y_pred_proba = classifier_dt.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_dt = model_evaluation(y_test, y_pred, y_pred_proba, \"Decision Tree\")\n",
    "classifier_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Decision Tree:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy       1.0      0.8428      0.1572\n",
      "1  Precision       1.0      0.1382      0.8618\n",
      "2     Recall       1.0      0.1805      0.8195\n",
      "3         F1       1.0      0.1566      0.8434\n",
      "4         F2       1.0      0.1701      0.8299\n",
      "5    ROC AUC       1.0      0.5408      0.4592\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.4592\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_dt.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_dt.predict(X_test)\n",
    "y_pred_proba = classifier_dt.predict_proba(X_test)\n",
    "check_model_fit(\n",
    "    classifier_dt,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Decision Tree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.00728</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.721932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0  Random Forest  0.919255        0.6  0.003662   0.00728  0.004571   \n",
       "\n",
       "   roc_auc_score  \n",
       "0       0.721932  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_rf.predict(X_test)\n",
    "y_pred_proba = classifier_rf.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_rf = model_evaluation(y_test, y_pred, y_pred_proba, \"Random Forest\")\n",
    "classifier_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Random Forest:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy       1.0      0.9192      0.0808\n",
      "1  Precision       1.0      0.5806      0.4194\n",
      "2     Recall       1.0      0.0037      0.9963\n",
      "3         F1       1.0      0.0073      0.9927\n",
      "4         F2       1.0      0.0046      0.9954\n",
      "5    ROC AUC       1.0      0.7224      0.2776\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2776\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_rf.predict(X_test)\n",
    "y_pred_proba = classifier_rf.predict_proba(X_test)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_rf,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM (Gradient Boosting Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 223500, number of negative: 223500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 44142\n",
      "[LightGBM] [Info] Number of data points in the train set: 447000, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Light GBM</td>\n",
       "      <td>0.918876</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>0.036719</td>\n",
       "      <td>0.02366</td>\n",
       "      <td>0.760155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Precision    Recall  F1 Score  F2 Score  roc_auc_score\n",
       "0  Light GBM  0.918876   0.458537  0.019125  0.036719   0.02366       0.760155"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lgbm = X_train_over.copy()\n",
    "X_test_lgbm = X_test.copy()\n",
    "\n",
    "X_train_lgbm.columns = X_train_lgbm.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '', regex=True)\n",
    "X_test_lgbm.columns = X_test_lgbm.columns.str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '', regex=True)\n",
    "\n",
    "classifier_lgbm = LGBMClassifier()\n",
    "classifier_lgbm.fit(X_train_lgbm, y_train_over)\n",
    "y_pred = classifier_lgbm.predict(X_test_lgbm)\n",
    "y_pred_proba = classifier_lgbm.predict_proba(X_test_lgbm)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_lgbm = model_evaluation(y_test, y_pred, y_pred_proba, \"Light GBM\")\n",
    "classifier_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 223500, number of negative: 223500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 44142\n",
      "[LightGBM] [Info] Number of data points in the train set: 447000, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model Fit Analysis for Light GBM:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9554      0.9189      0.0365\n",
      "1  Precision    0.9982      0.4585      0.5397\n",
      "2     Recall    0.9125      0.0191      0.8933\n",
      "3         F1    0.9534      0.0367      0.9167\n",
      "4         F2    0.9284      0.0237      0.9047\n",
      "5    ROC AUC    0.9808      0.7602      0.2207\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2207\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_lgbm = LGBMClassifier()\n",
    "classifier_lgbm.fit(X_train_lgbm, y_train_over)\n",
    "y_pred = classifier_lgbm.predict(X_test_lgbm)\n",
    "y_pred_proba = classifier_lgbm.predict_proba(X_test_lgbm)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_lgbm,\n",
    "    X_train_lgbm,\n",
    "    X_test_lgbm,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Light GBM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>0.900717</td>\n",
       "      <td>0.239181</td>\n",
       "      <td>0.104578</td>\n",
       "      <td>0.145527</td>\n",
       "      <td>0.117841</td>\n",
       "      <td>0.685228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Precision    Recall  F1 Score  F2 Score  roc_auc_score\n",
       "0  Ada Boost  0.900717   0.239181  0.104578  0.145527  0.117841       0.685228"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ab = AdaBoostClassifier()\n",
    "classifier_ab.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_ab.predict(X_test)\n",
    "y_pred_proba = classifier_ab.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_ab = model_evaluation(y_test, y_pred, y_pred_proba, \"Ada Boost\")\n",
    "classifier_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for Ada Boost:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9290      0.9007      0.0283\n",
      "1  Precision    0.9668      0.2392      0.7276\n",
      "2     Recall    0.8885      0.1046      0.7839\n",
      "3         F1    0.9260      0.1455      0.7805\n",
      "4         F2    0.9031      0.1178      0.7853\n",
      "5    ROC AUC    0.9669      0.6852      0.2816\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2816\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_ab = AdaBoostClassifier()\n",
    "classifier_ab.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_ab.predict(X_test)\n",
    "y_pred_proba = classifier_ab.predict_proba(X_test)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_ab,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"Ada Boost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Boost</td>\n",
       "      <td>0.918613</td>\n",
       "      <td>0.466119</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>0.084043</td>\n",
       "      <td>0.056336</td>\n",
       "      <td>0.75276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Precision    Recall  F1 Score  F2 Score  roc_auc_score\n",
       "0  XGB Boost  0.918613   0.466119  0.046185  0.084043  0.056336        0.75276"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_xgb.predict(X_test)\n",
    "y_pred_proba = classifier_xgb.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "classifier_xgb = model_evaluation(y_test, y_pred, y_pred_proba, \"XGB Boost\")\n",
    "classifier_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fit Analysis for XGB Boost:\n",
      "      Metric  Training  Validation  Difference\n",
      "0   Accuracy    0.9586      0.9186      0.0400\n",
      "1  Precision    0.9978      0.4661      0.5317\n",
      "2     Recall    0.9193      0.0462      0.8731\n",
      "3         F1    0.9570      0.0840      0.8729\n",
      "4         F2    0.9340      0.0563      0.8777\n",
      "5    ROC AUC    0.9868      0.7528      0.2341\n",
      "\n",
      "Analisis:\n",
      "⚠️ Model menunjukkan tanda OVERFITTING\n",
      "    selisih metrics training-validation: 0.2341\n",
      "   - Model terlalu 'menghapal' data training\n",
      "   - Performa di validation jauh lebih rendah\n"
     ]
    }
   ],
   "source": [
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(X_train_over, y_train_over)\n",
    "y_pred = classifier_xgb.predict(X_test)\n",
    "y_pred_proba = classifier_xgb.predict_proba(X_test)\n",
    "\n",
    "check_model_fit(\n",
    "    classifier_xgb,\n",
    "    X_train_over,\n",
    "    X_test,\n",
    "    y_train_over,\n",
    "    y_test,\n",
    "    \"XGB Boost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypeparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 223500, number of negative: 223500\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44142\n",
      "[LightGBM] [Info] Number of data points in the train set: 447000, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'class_weight': 'balanced', 'colsample_bytree': np.float64(0.9186171947440931), 'learning_rate': np.float64(0.06503043695984914), 'max_depth': 7, 'min_child_samples': 21, 'n_estimators': 202, 'num_leaves': 94, 'subsample': np.float64(0.7836995567863468)}\n",
      "Best CV ROC AUC score: 0.968591413599988\n",
      "\n",
      "Metrics Comparison:\n",
      "Metric               Train       Test Difference\n",
      "---------------------------------------------\n",
      "accuracy             0.957      0.919      0.038\n",
      "precision            0.999      0.531      0.468\n",
      "recall               0.916      0.026      0.889\n",
      "roc_auc              0.986      0.760      0.226\n",
      "\n",
      "Detailed Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     55881\n",
      "         1.0       0.53      0.03      0.05      4915\n",
      "\n",
      "    accuracy                           0.92     60796\n",
      "   macro avg       0.73      0.51      0.50     60796\n",
      "weighted avg       0.89      0.92      0.88     60796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Define the parameter space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'num_leaves': randint(20, 100),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_samples': randint(1, 50),\n",
    "    'class_weight': ['balanced', {0: 1, 1: 11.3}]\n",
    "}\n",
    "\n",
    "# Create base model\n",
    "model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Setup RandomizedSearchCV with ROC AUC scoring\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',  # Use ROC AUC for optimization\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best CV ROC AUC score:\", random_search.best_score_)\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Calculate metrics for both train and test sets\n",
    "def get_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y, y_pred),\n",
    "        'precision': precision_score(y, y_pred),\n",
    "        'recall': recall_score(y, y_pred),\n",
    "        'roc_auc': roc_auc_score(y, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Get metrics for both sets\n",
    "train_metrics = get_metrics(best_model, X_train_over, y_train_over)\n",
    "test_metrics = get_metrics(best_model, X_test, y_test)\n",
    "\n",
    "# Print metrics comparison\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "print(f\"{'Metric':<15} {'Train':>10} {'Test':>10} {'Difference':>10}\")\n",
    "print(\"-\" * 45)\n",
    "for metric in train_metrics.keys():\n",
    "    diff = train_metrics[metric] - test_metrics[metric]\n",
    "    print(f\"{metric:<15} {train_metrics[metric]:>10.3f} {test_metrics[metric]:>10.3f} {diff:>10.3f}\")\n",
    "\n",
    "# Print detailed classification report for test set\n",
    "print(\"\\nDetailed Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM give the best performance between other algorithms but after we try to hyperparameter tuning, the score still overfitting and bias to class 0. Although the accuracy is 0.919, but the score is misleading due to class imbalance extreme. Next, we will try hyperparameter tuning on XGBoost as the second best score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': np.float64(0.07969454818643935), 'class_weight': 'balanced', 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best ROC AUC Score: 0.7737343916039817\n",
      "\n",
      "=== Training Set Metrics ===\n",
      "Accuracy: 0.7076\n",
      "Precision: 0.7041\n",
      "Recall: 0.7163\n",
      "ROC AUC: 0.7744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156204  67296]\n",
      " [ 63402 160098]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.70      0.71    223500\n",
      "         1.0       0.70      0.72      0.71    223500\n",
      "\n",
      "    accuracy                           0.71    447000\n",
      "   macro avg       0.71      0.71      0.71    447000\n",
      "weighted avg       0.71      0.71      0.71    447000\n",
      "\n",
      "\n",
      "=== Testing Set Metrics ===\n",
      "Accuracy: 0.6982\n",
      "Precision: 0.1659\n",
      "Recall: 0.6787\n",
      "ROC AUC: 0.7540\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39111 16770]\n",
      " [ 1579  3336]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.70      0.81     55881\n",
      "         1.0       0.17      0.68      0.27      4915\n",
      "\n",
      "    accuracy                           0.70     60796\n",
      "   macro avg       0.56      0.69      0.54     60796\n",
      "weighted avg       0.90      0.70      0.77     60796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "# Parameter tuning\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-3, 1e-1),\n",
    "    'max_iter': [200],\n",
    "    'solver': ['liblinear'],\n",
    "    'penalty': ['l1'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Define scoring metrics for RandomizedSearchCV\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "lr = LogisticRegression(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    lr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring=scoring,\n",
    "    refit='roc_auc',  # Optimize for ROC AUC\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "def evaluate_model(model, X, y, dataset_name):\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    class_report = classification_report(y, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {dataset_name} Set Metrics ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best ROC AUC Score:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on both train and test sets\n",
    "evaluate_model(best_model, X_train_over, y_train_over, \"Training\")\n",
    "evaluate_model(best_model, X_test, y_test, \"Testing\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
